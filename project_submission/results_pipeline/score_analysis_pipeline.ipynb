{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "score_analysis_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN80GfKtcOquDsZmVCuohxa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV-5PTERVQ4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages:\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random \n",
        "import datetime\n",
        "from re import search\n",
        "from datetime import date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwKrvmdMAvRo",
        "colab_type": "text"
      },
      "source": [
        "##### Reading and organizing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b7ezEb2XR9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in model metadata:\n",
        "metadata_Black = pd.read_csv('metadata_unlabeled_appeal_black.csv')\n",
        "metadata_Black = metadata_Black.rename(columns = {'pred': 'pred_Black'}).drop(columns = ['src_path'])\n",
        "metadata_Hispanic = pd.read_csv('metadata_unlabeled_appeal_hispanic.csv')\n",
        "metadata_Hispanic = metadata_Hispanic.rename(columns = {'pred': 'pred_Hispanic'}).drop(columns = ['src_path'])\n",
        "metadata_Asian = pd.read_csv('metadata_unlabeled_appeal_asian.csv')\n",
        "metadata_Asian = metadata_Asian.rename(columns = {'pred': 'pred_Asian'}).drop(columns = ['src_path'])\n",
        "metadata_LGBTQ = pd.read_csv('metadata_unlabeled_appeal_lgbtq+.csv')\n",
        "metadata_LGBTQ = metadata_LGBTQ.rename(columns = {'pred': 'pred_lgbtq'}).drop(columns = ['src_path'])\n",
        "\n",
        "# merge model metadata into a single DataFrame; make sure all rows merge correctly:\n",
        "metadata = metadata_Black.merge(metadata_Hispanic.merge(metadata_Asian.merge(metadata_LGBTQ, on = ['tgt_path', 'caption']), on = ['tgt_path', 'caption']), on = ['tgt_path', 'caption']).rename(columns = {'tgt_path': 'filename'})\n",
        "assert metadata.shape[0] == metadata_Black.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8CDeldpvrDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in politician metadata:\n",
        "pol_metadata = pd.read_csv('politician_metadata.csv')\n",
        "pol_metadata['Name'] = pol_metadata['Name'].apply(lambda x: x.strip())\n",
        "\n",
        "# store politician name in model metadata and merge DataFrames:\n",
        "politicians = []\n",
        "n = metadata.shape[0]\n",
        "for i in range(n):\n",
        "  name = metadata.iloc[i]['filename'].split('_')[3].strip()\n",
        "  politicians.append(name)\n",
        "metadata['Name'] = politicians\n",
        "data = metadata.merge(pol_metadata, on='Name')\n",
        "# make sure all rows merge:\n",
        "assert data.shape[0] == metadata.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLNLQkqpKGX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in data for 2015 Census Bureau Congressional District and State demographic estimates:\n",
        "os.chdir(\"/content/drive/My Drive/GSOC2020/Training Model\")\n",
        "dist_makeup = pd.read_csv('congressional_dist_makeup.csv', thousands=',')\n",
        "state_makeup = pd.read_csv('state_makeup.csv')\n",
        "\n",
        "# create columns storing the proportion of state/district population that is Black, Hispanic, Asian, and non-white:\n",
        "dist_makeup['prop_Black'] = pd.to_numeric(dist_makeup['Black or African American']) / pd.to_numeric(dist_makeup['Total'])\n",
        "dist_makeup['prop_Hispanic'] = pd.to_numeric(dist_makeup['Hispanic or Latino of any race']) / pd.to_numeric(dist_makeup['Total'])\n",
        "dist_makeup['prop_Asian'] = pd.to_numeric(dist_makeup['Asian']) / pd.to_numeric(dist_makeup['Total'])\n",
        "dist_makeup['prop_nonwhite'] = (pd.to_numeric(dist_makeup['Total']) - pd.to_numeric(dist_makeup['White'])) / pd.to_numeric(dist_makeup['Total'])\n",
        "\n",
        "state_makeup['Black or\\nAfrican American'] = state_makeup['Black or\\nAfrican American'].str.strip('%').astype(float) / 100\n",
        "state_makeup['Hispanic/Latino'] = state_makeup['Hispanic/Latino'].str.strip('%').astype(float) / 100\n",
        "state_makeup['Asian'] = state_makeup['Asian'].str.strip('%').astype(float) / 100\n",
        "state_makeup['prop_nonwhite'] = 1 - (state_makeup['White'].str.strip('%').astype(float) / 100)\n",
        "state_makeup = state_makeup.rename(columns= {'State or territory': 'District', 'Black or\\nAfrican American': 'prop_Black', 'Hispanic/Latino': 'prop_Hispanic', 'Asian': 'prop_Asian', 'Population\\n(2015 est.)': 'Total'})\n",
        "demographic_df = pd.concat([dist_makeup, state_makeup]).dropna(axis=1).drop(columns=['White'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxs9yJqEXXR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge Demographic df with original df:\n",
        "def House_abbr(i):\n",
        "  if data.iloc[i]['District'].strip() == \"at-large\":\n",
        "    return (data.iloc[i]['state'] + \"00\")\n",
        "  else:\n",
        "    if int(data.iloc[i]['District']) < 10:\n",
        "      return (data.iloc[i]['state'] + f\"0{data.iloc[i]['District']}\")\n",
        "    else:\n",
        "      return (data.iloc[i]['state'] + f\"{data.iloc[i]['District']}\")\n",
        "\n",
        "district_list = []\n",
        "n = data.shape[0]\n",
        "for i in range(n):\n",
        "  if data.iloc[i]['Election'].strip() == 'House':\n",
        "    district_list.append(House_abbr(i))\n",
        "  else:\n",
        "    district_list.append(data.iloc[i]['state'].strip())\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "data['District_abbr'] = district_list\n",
        "demographic_df = demographic_df.rename(columns={'District': 'District_abbr'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp1jLXYFZ6qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge demographic data with model scores; make sure all rows correctly merge:\n",
        "n = data.shape[0]\n",
        "data = data.merge(demographic_df, on = 'District_abbr')\n",
        "assert data.shape[0] == n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jR1TiBcbXpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add columns to indicate whether each politician belongs to a particular underrepresented group:\n",
        "n = data.shape[0]\n",
        "is_Black = np.zeros(n)\n",
        "is_Hispanic = np.zeros(n)\n",
        "is_Asian = np.zeros(n)\n",
        "is_nonwhite = np.zeros(n)\n",
        "\n",
        "for i in range(n):\n",
        "  race = data.iloc[i]['Race'].lower()\n",
        "  if search('black|blck|african-american', race) != None:\n",
        "    is_Black[i] += 1\n",
        "\n",
        "  if search('latino|hispanic|puerto rican|mexican', race) != None:\n",
        "    is_Hispanic[i] += 1\n",
        "  \n",
        "  if search('asian', race) != None:\n",
        "    is_Asian[i] += 1\n",
        "\n",
        "  if search('white', race) == None:\n",
        "    is_nonwhite[i] += 1\n",
        "\n",
        "data['is_Black'] = list(is_Black)\n",
        "data['is_Hispanic'] = list(is_Hispanic)\n",
        "data['is_Asian'] = list(is_Asian)\n",
        "data['is_nonwhite'] = list(is_nonwhite)\n",
        "\n",
        "data['is_Black'] = data['is_Black'].astype(int)\n",
        "data['is_Hispanic'] = data['is_Hispanic'].astype(int)\n",
        "data['is_Asian'] = data['is_Asian'].astype(int)\n",
        "data['is_nonwhite'] = data['is_nonwhite'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KkU94QJBTOI",
        "colab_type": "text"
      },
      "source": [
        "##### Regression analysis:\n",
        "\n",
        "###### Justification for multiple linear regression:\n",
        "Unlike in previous Logistic regression analysis predicting a nominal appeal variable (ex. 1 = yes 'Asian_appeal', 0 = no), linear regression is used to predict the appeal scores of Facebook images, measured continuously from 0 to 1. The model used is $y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}+ ...\\beta_k x_{ik}$ where $(x_1, y_1), ...., (x_n, y_n)$ are independent observations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx-5YGlBF9-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2fhYIPqNzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_hist(OLS_model, y_val):\n",
        "  y_hat = model.fittedvalues.copy()\n",
        "  residual = y_val - y_hat\n",
        "  plt.hist(residual, bins=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnDNp6wMGz6Y",
        "colab_type": "text"
      },
      "source": [
        "Assumptions for multiple linear regression:\n",
        "\n",
        "\n",
        "*   Linearity between predictors and independent r.v.\n",
        "*   Nonsingularity of $X^TX$, where $X$ is the matrix of predictors such that $X \\in M_{n \\times k}(R)$; this is equivalent to no multicollinearity between predictors\n",
        "*   For a fixed $X = x$, the error $\\epsilon$ is normally distributed as $N(\\mu, \\sigma^2)$, where $\\mu = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}+ ...\\beta_k x_{ik}$\n",
        "*   The variance in the errors $\\epsilon$, $\\sigma^2$, is constant for all $X = x$ (i.e. errors may have different mean but same variance)\n",
        "\n",
        "\\* Note: As the distributions of errors in approximation are unknown, we estimate them by the residuals.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KErsWXIZMpH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the distribution of the four appeal variables:\n",
        "\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "fig.suptitle('Untransformed score distributions')\n",
        "axs[0, 0].hist(data['pred_Black'])\n",
        "axs[0, 0].set_title('Black_appeal scores')\n",
        "axs[0, 1].hist(data['pred_Hispanic'])\n",
        "axs[0, 1].set_title('Hispanic_appeal scores')\n",
        "axs[1, 0].hist(data['pred_Asian'])\n",
        "axs[1, 0].set_title('Asian_appeal scores')\n",
        "axs[1, 1].hist(data['pred_lgbtq'])\n",
        "axs[1, 1].set_title('LGBTQ+_appeal scores')\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EprE6oVswmWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "fig.suptitle('Transformed score distributions')\n",
        "axs[0, 0].hist(np.sqrt(data['pred_Black']))\n",
        "axs[0, 0].set_title('sqrt(Black_appeal) scores')\n",
        "axs[0, 1].hist(np.log(data['pred_Hispanic']))\n",
        "axs[0, 1].set_title('log(Hispanic_appeal) scores')\n",
        "axs[1, 0].hist(np.log(data['pred_Asian']))\n",
        "axs[1, 0].set_title('log(Asian_appeal) scores')\n",
        "axs[1, 1].hist(np.sqrt(data['pred_lgbtq']))\n",
        "axs[1, 1].set_title('sqrt(LGBTQ+_appeal) scores')\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dE50upeHmFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['win'] = data['win'].astype(str)\n",
        "data['win'] = data['win'].apply(lambda x: x.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B06WJgThgNm",
        "colab_type": "text"
      },
      "source": [
        "What is issue with keeping individual politician images as observations? Predictors are highly dependent (ex. if img1 shared by Alexandria Ocasio-Cortez has 'is_Hispanic' = 1, for any other image she shares 'is_Hispanic' will also be equal to 1)\n",
        "\n",
        "* Solution: take average of scores across all images shared by each politician"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ5g3i6VZLtt",
        "colab_type": "text"
      },
      "source": [
        "###### i. Predicting Democratic appeal to Black voters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juQTvcOqiwl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take average of 'Black_appeal' scores across all images shared by each politician:\n",
        "data['num_imgs'] = np.ones(data.shape[0])\n",
        "politician_group = data.groupby(by='Name')\n",
        "politician_group = politician_group.sum()\n",
        "columns = list(politician_group.columns)\n",
        "n = len(columns) - 1\n",
        "ints = [4, 9, 10, 11, 12]\n",
        "politician_group['num_imgs'] = politician_group['num_imgs'].astype(int)\n",
        "for i in range(n):\n",
        "  politician_group[f'{columns[i]}'] = politician_group[f'{columns[i]}'] / politician_group['num_imgs']\n",
        "  if i in ints:\n",
        "    politician_group[f'{columns[i]}'] = politician_group[f'{columns[i]}'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbchDJXALI2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at the distributions of the average predicted appeal scores by politician:\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "fig.suptitle('Untransformed score distributions')\n",
        "axs[0, 0].hist(politician_group['pred_Black'], bins = 20)\n",
        "axs[0, 0].set_title('avg Black_appeal scores')\n",
        "axs[0, 1].hist(politician_group['pred_Hispanic'], bins = 20)\n",
        "axs[0, 1].set_title('avg Hispanic_appeal scores')\n",
        "axs[1, 0].hist(politician_group['pred_Asian'], bins = 20)\n",
        "axs[1, 0].set_title('avg Asian_appeal scores')\n",
        "axs[1, 1].hist(politician_group['pred_lgbtq'], bins = 20)\n",
        "axs[1, 1].set_title('avg LGBTQ+_appeal scores')\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlfnrHMOvAip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display distributions of predictors \n",
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "axs[0].hist(politician_group['prop_Black'])\n",
        "axs[0].set_title('Distribution of prop_Black')\n",
        "axs[1].hist(politician_group['is_Black'])\n",
        "axs[1].set_title('Distribution of is_Black')\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9TMQwse2d-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "axs[0].scatter(politician_group['prop_Black'], politician_group['pred_Black'])\n",
        "axs[0].set_title('prop_Black v. pred_Black')\n",
        "axs[1].scatter(politician_group['is_Black'], politician_group['pred_Black'])\n",
        "axs[1].set_title('is_Black v. pred_Black')\n",
        "fig.tight_layout(pad=3.0)\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XxQxhTmzoxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = politician_group[['prop_Black', 'is_Black']]\n",
        "predictors.corr().style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivePBfTg1mEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = sm.add_constant(predictors)\n",
        "pd.Series([variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])], index=predictors.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hR6zaoKegkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = politician_group['pred_Black'].to_numpy()\n",
        "x = np.array(list(zip(politician_group['prop_Black'].to_list(), politician_group['is_Black'].to_list())))\n",
        "x = sm.add_constant(x)\n",
        "model = sm.OLS(y, x)\n",
        "model = model.fit()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPt6tG8T379Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "residual_hist(model, politician_group['pred_Black'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PketoDvL4b3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.residplot(politician_group['prop_Black'], politician_group['pred_Black'], lowess=True, color=\"g\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWFZyzH0544e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.residplot(politician_group['is_Black'], politician_group['pred_Black'], lowess=True, color=\"g\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUP9Epn1YtDi",
        "colab_type": "text"
      },
      "source": [
        "###### ii. Predicting Democratic appeal to Hispanic voters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZI0qypXY6HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "axs[0].hist(politician_group['prop_Hispanic'])\n",
        "axs[0].set_title('Distribution of prop_Hispanic')\n",
        "axs[1].hist(politician_group['is_Hispanic'])\n",
        "axs[1].set_title('Distribution of is_Hispanic')\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC8hJ5_2aEh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "axs[0].scatter(politician_group['prop_Hispanic'], politician_group['pred_Hispanic'])\n",
        "axs[0].set_title('prop_Hispanic v. pred_Hispanic')\n",
        "axs[1].scatter(politician_group['is_Hispanic'], politician_group['pred_Hispanic'])\n",
        "axs[1].set_title('is_Hispanic v. pred_Hispanic')\n",
        "fig.tight_layout(pad=3.0)\n",
        "fig.tight_layout(pad=3.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpyftGY9aguP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = politician_group[['prop_Hispanic', 'is_Hispanic']]\n",
        "predictors.corr().style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bt-9r3Earqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = sm.add_constant(predictors)\n",
        "pd.Series([variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])], index=predictors.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLNXkAXQbF1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = politician_group['pred_Hispanic'].to_numpy()\n",
        "x = np.array(list(zip(politician_group['prop_Hispanic'].to_list(), politician_group['is_Hispanic'].to_list())))\n",
        "x = sm.add_constant(x)\n",
        "model = sm.OLS(y, x)\n",
        "model = model.fit()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0KxmkSbrHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "residual_hist(model, politician_group['pred_Hispanic'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f07JJNG2b4cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.residplot(politician_group['prop_Hispanic'], politician_group['pred_Hispanic'], lowess=True, color=\"g\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX1UrgQWcFl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.residplot(politician_group['is_Hispanic'], politician_group['pred_Hispanic'], lowess=True, color=\"g\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0601FmPuKLHb",
        "colab_type": "text"
      },
      "source": [
        "###### iii. Predict election outcome for politicians who ran in 2018:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfWuyrNuzlHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write function to compute and plot Pearson residuals:\n",
        "def pearson_resid(model_output, Y):\n",
        "  odds_ratio = output.fittedvalues\n",
        "  p_hat = np.exp(odds_ratio)/(1 + np.exp(odds_ratio))\n",
        "  se = np.sqrt(p_hat*(1 - p_hat))\n",
        "  pearson_residuals = (Y - p_hat)/se\n",
        "  plt.hist(pearson_residuals, bins=20)\n",
        "  plt.axvline(-2, 0, 5, color=\"red\", linewidth=1.5)\n",
        "  plt.axvline(2, 0, 5, color=\"red\", linewidth=1.5)\n",
        "  print(f'Pearson residual diagnostics: \\n mean = {np.mean(pearson_residuals)}, var = {np.var(pearson_residuals)}')\n",
        "  return pearson_residuals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPPrnTscKsrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store whether a politician won/lost their election:\n",
        "data['win'] = data['win'].astype(str)\n",
        "data['win'] = data['win'].apply(lambda x: x.strip())\n",
        "data_outcome = data.loc[(data.win == 'Y') | (data.win == 'N')]\n",
        "WL_map = {'Y': 1, 'N': 0}\n",
        "data_outcome['win'] = data_outcome['win'].map(WL_map)\n",
        "data_outcome['win'] = data_outcome['win'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fziJ25qALXDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group by politician and take the average predicted score across all images they shared:\n",
        "politician_outcome_group = data_outcome.groupby(by='Name')\n",
        "politician_outcome_group = politician_outcome_group.sum()\n",
        "columns = list(politician_outcome_group.columns)\n",
        "n = len(columns) - 1\n",
        "ints = [4, 5, 10, 11, 12, 13]\n",
        "politician_outcome_group['num_imgs'] = politician_outcome_group['num_imgs'].astype(int)\n",
        "for i in range(n):\n",
        "  politician_outcome_group[f'{columns[i]}'] = politician_outcome_group[f'{columns[i]}'] / politician_outcome_group['num_imgs']\n",
        "  if i in ints:\n",
        "    politician_outcome_group[f'{columns[i]}'] = politician_outcome_group[f'{columns[i]}'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kxOwwCLx0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict electoral outcome with a Logistic regression model using the four appeal variables as predictors:\n",
        "pred_Black = politician_outcome_group['pred_Black'].tolist()\n",
        "pred_Hispanic = politician_outcome_group['pred_Hispanic'].tolist()\n",
        "pred_Asian = politician_outcome_group['pred_Asian'].tolist()\n",
        "pred_LGBTQ = politician_outcome_group['pred_lgbtq'].tolist()\n",
        "\n",
        "predictors = np.array(list(zip(pred_Black, pred_Hispanic, pred_Asian, pred_LGBTQ)))\n",
        "predictors = sm.add_constant(predictors)\n",
        "logistic_model = sm.Logit(politician_outcome_group['win'], predictors)\n",
        "output = logistic_model.fit()\n",
        "print(output.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP5JsGvPBv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# look at potential multicollinearity between predictors\n",
        "predictors = politician_outcome_group[['pred_Black', 'pred_Hispanic', 'pred_Asian', 'pred_lgbtq']]\n",
        "predictors.corr().style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2guxqJoGO0oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = sm.add_constant(predictors)\n",
        "pd.Series([variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])], index=predictors.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mpKuqvdRQqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logistic regression assumes linearity between predictors and the lod-odds:\n",
        "log_odds = output.fittedvalues\n",
        "group = ['pred_Black', 'pred_Hispanic', 'pred_Asian', 'pred_lgbtq']\n",
        "\n",
        "for i in range(4):\n",
        "  a = plt.figure(i)\n",
        "  plt.scatter(politician_outcome_group[f'{group[i]}'], log_odds)\n",
        "  group_scatter = politician_outcome_group[f'{group[i]}'].to_numpy()\n",
        "  slp, intc = np.polyfit(group_scatter, log_odds, 1)\n",
        "  # line-of-best fit shown in red\n",
        "  plt.plot(group_scatter, slp*group_scatter + intc, 'r')\n",
        "  plt.title(f'Log-odds v. avg {group[i]}')\n",
        "  a.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MknJWn-ltH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pearson_resid1 = pearson_resid(output, politician_outcome_group['win'].to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVyKRmXxXU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# there seem to be quite a few outlier values... exclude vals with pearson residuals > 2 from logistic model:\n",
        "exclude = np.abs(pearson_resid1) > 2 \n",
        "exclude = exclude.loc[exclude == True].index.values.tolist()\n",
        "politician_outcome_group = politician_outcome_group.reset_index()\n",
        "include = politician_outcome_group[~politician_outcome_group.Name.isin(exclude)]\n",
        "\n",
        "# run Logistic regression again excluding these values (politicians):\n",
        "pred_Black = np.log(include['pred_Black'].tolist())\n",
        "pred_Hispanic = include['pred_Hispanic'].tolist()\n",
        "pred_Asian = include['pred_Asian'].tolist()\n",
        "pred_LGBTQ = include['pred_lgbtq'].tolist()\n",
        "\n",
        "predictors = np.array(list(zip(pred_Black, pred_Hispanic, pred_Asian, pred_LGBTQ)))\n",
        "predictors = sm.add_constant(predictors)\n",
        "logistic_model = sm.Logit(include['win'], predictors)\n",
        "output = logistic_model.fit()\n",
        "print(output.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaLiy2pvxHV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pearson_resid2 = pearson_resid(output, include['win'].to_numpy()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKOItsSFvNXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in Logistic regression there should be no relationship between predictors and Pearson residuals:\n",
        "f = plt.figure(1)\n",
        "plt.scatter(pred_Black, pearson_resid2)\n",
        "plt.hlines(0, min(pred_Black), max(pred_Black), linestyles='dashed')\n",
        "slp, intc = np.polyfit(pred_Black, pearson_resid2, 1)\n",
        "pred_Black = np.array(pred_Black)\n",
        "# line-of-best fit shown in red\n",
        "plt.plot(pred_Black, slp*pred_Black + intc, 'r')\n",
        "plt.title('Pearson residuals v. avg predicted Black appeal scores')\n",
        "f.show()\n",
        "\n",
        "g = plt.figure(2)\n",
        "plt.scatter(pred_Hispanic, pearson_resid2)\n",
        "plt.hlines(0, min(pred_Hispanic), max(pred_Hispanic), linestyles='dashed')\n",
        "plt.title('Pearson residuals v. avg predicted Hispanic appeal scores')\n",
        "g.show()\n",
        "\n",
        "h = plt.figure(3)\n",
        "plt.scatter(output.fittedvalues, pearson_resid2)\n",
        "plt.hlines(0, output.fittedvalues.min(), output.fittedvalues.max(), linestyles='dashed')\n",
        "plt.title('Pearson residuals v. fitted log-odds values')\n",
        "h.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Tk2pcJDgsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try fitting a quadratic model:\n",
        "# not hopeful: \n",
        "pred_Hispanic = np.square(np.array(include['pred_Hispanic']))\n",
        "predictors = np.array(list(zip(pred_Black, pred_Hispanic, pred_Asian, pred_LGBTQ)))\n",
        "predictors = sm.add_constant(predictors)\n",
        "logistic_model = sm.Logit(include['win'], predictors)\n",
        "output = logistic_model.fit()\n",
        "print(output.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re-a9-zjHDmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pearson_resid3 = pearson_resid(output, include['win'].to_numpy())\n",
        "\n",
        "g = plt.figure(2)\n",
        "plt.scatter(pred_Hispanic, pearson_resid3)\n",
        "plt.hlines(0, min(pred_Hispanic), max(pred_Hispanic), linestyles='dashed')\n",
        "plt.title('Pearson residuals v. avg predicted Hispanic appeal scores')\n",
        "g.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIk9ShU5WADY",
        "colab_type": "text"
      },
      "source": [
        "##### Temporal Analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POD4FEUjRCRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in primary election data:\n",
        "primary_dates = pd.read_csv('2018_congressional_primary_dates.csv')\n",
        "primary_datetime = [f\"2018-{primary_dates.iloc[i]['Month']}-{primary_dates.iloc[i]['Day']}\" for i in range(primary_dates.shape[0])]\n",
        "primary_dates['primary_datetime'] = primary_datetime\n",
        "primary_dates['primary_datetime'] = pd.to_datetime(primary_dates['primary_datetime'], infer_datetime_format=True).apply(lambda col: col.date())\n",
        "\n",
        "# merge on state:\n",
        "primary_dates = primary_dates.rename(columns={'State':'state'})\n",
        "n = data.shape[0]\n",
        "data = data.merge(primary_dates, on='state')\n",
        "# make sure all rows correctly merge\n",
        "assert data.shape[0] == n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im05f_h5WDP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('Dataset Analysis/metadata')\n",
        "# merge data recording each politician's primary date with the existing data:\n",
        "time_data = pd.read_csv('2018_img_metadata_final.csv')\n",
        "time_data = time_data[['filename', 'post_time']]\n",
        "# normalize filename strings by removing accents to make sure all rows correctly merge\n",
        "n = data.shape[0]\n",
        "data = data.merge(time_data, on='filename').drop_duplicates()\n",
        "\n",
        "# make sure all rows correctly merge:\n",
        "assert data.shape[0] == n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWLVe9DJGSGZ",
        "colab_type": "text"
      },
      "source": [
        "###### Facebook Image Temporal Frequency:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1oCS8lwEfYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make 'post_time' of dtype DateTime:\n",
        "data['post_time'] = pd.to_datetime(data['post_time'])\n",
        "data['num_imgs'] = data['num_imgs'].astype(int)\n",
        "month_groups = data.groupby(pd.Grouper(key='post_time', freq='1M')).sum()\n",
        "\n",
        "# plot number of images shared per month:\n",
        "num_imgs_monthly = month_groups['num_imgs'].tolist()\n",
        "month_abbrv = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "a = plt.figure(1)\n",
        "plt.plot(month_abbrv, num_imgs_monthly)\n",
        "plt.title('Images posted to FB per Month by Democratic Politicians')\n",
        "a.show()\n",
        "\n",
        "# plot number of images shared per month:\n",
        "day_groups = data.groupby('post_time').sum().reset_index()\n",
        "num_imgs_daily = day_groups['num_imgs'].tolist()\n",
        "days = day_groups['post_time'].tolist()\n",
        "days = [x.to_pydatetime().date() for x in days]\n",
        "\n",
        "b = plt.figure(2)\n",
        "fig, ax = plt.subplots(1)\n",
        "# format x-axis to plot dates\n",
        "fig.autofmt_xdate()\n",
        "plt.plot(days, num_imgs_daily)\n",
        "plt.title('Images posted to FB per Day by Democratic Politicians')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwIClO38O20D",
        "colab_type": "text"
      },
      "source": [
        "###### Normalized Predicted Appeal Temporal Frequency:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMj0YDESO2RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Black_appeal:\n",
        "# plot average predicted Black appeal score of imgs shared to FB by month:\n",
        "Black_appl_monthly = (month_groups['pred_Black'] /  month_groups['num_imgs']).tolist()\n",
        "\n",
        "a = plt.figure(1)\n",
        "plt.plot(month_abbrv, Black_appl_monthly)\n",
        "plt.title('Average Predicted Black_appeal per Month by Democratic Politicians')\n",
        "a.show()\n",
        "\n",
        "# plot average predicted Black appeal score of imgs shared to FB by day:\n",
        "Black_appl_daily = (day_groups['pred_Black'] / day_groups['num_imgs']).tolist()\n",
        "\n",
        "b = plt.figure(2)\n",
        "fig, ax = plt.subplots(1)\n",
        "# format x-axis to plot dates\n",
        "fig.autofmt_xdate()\n",
        "plt.plot(days, Black_appl_daily)\n",
        "plt.title('Average Predicted Black_appeal per Day by Democratic Politicians')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzASby7MUxHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = data.shape[0]\n",
        "\n",
        "# store number of days image was posted before/after the politician's primary election:\n",
        "data['days_until_primary'] = [(data.iloc[i]['post_time'].date() - data.iloc[i]['primary_datetime']).days for i in range(n)]\n",
        "data['days_until_primary'] = data['days_until_primary'].astype(int)\n",
        "\n",
        "# before/after the politician's general election:\n",
        "data['days_until_general'] = [(data.iloc[i]['post_time'].date() - datetime.date(2018, 11, 6)).days for i in range(n)]\n",
        "data['days_until_general'] = data['days_until_general'].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dY-ZybWUjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get images posted a month before and after primary election\n",
        "month_prior_primary = data.loc[(-30 <= data.days_until_primary) & (data.days_until_primary < 0)]\n",
        "month_post_primary = data.loc[(0 < data.days_until_primary) & (data.days_until_primary <= 30)]\n",
        "\n",
        "month_prior_primary = month_prior_primary.groupby('Name').sum().reset_index()\n",
        "month_post_primary = month_post_primary.groupby('Name').sum().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urchA1Q2eSTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only consider politicians who post both in the month before and after primary\n",
        "names1 = month_prior_primary['Name'].tolist()\n",
        "names2 = month_post_primary['Name'].tolist()\n",
        "\n",
        "include = [name for name in names1 if name in names2] \n",
        "\n",
        "month_prior_primary = month_prior_primary[month_prior_primary.Name.isin(include)].reset_index().drop(columns=['index'])\n",
        "month_post_primary = month_post_primary[month_post_primary.Name.isin(include)].reset_index().drop(columns=['index'])\n",
        "\n",
        "month_prior_primary = month_prior_primary.sort_values('Name')\n",
        "month_post_primary = month_post_primary.sort_values('Name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVN2aslhkvlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate differences in avg Black appeal by Democrats (post - pre-primary):\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "ttest_rel((month_prior_primary['pred_Black'] / month_prior_primary['num_imgs']), (month_post_primary['pred_Black'] / month_post_primary['num_imgs']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWAZ63i7rXN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.corrcoef((month_prior_primary['pred_Black'] / month_prior_primary['num_imgs']), (month_post_primary['pred_Black'] / month_post_primary['num_imgs']))[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "441fT0dxn-ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the paired t-test necessitates that the underlying distributions (month prior, month post) of avg Black appeal scores are normally distributed:\n",
        "a = plt.figure(1)\n",
        "plt.hist((month_prior_primary['pred_Black'] / month_prior_primary['num_imgs']))\n",
        "plt.title('Dist of avg Black appeal scores by politician one month prior to primary')\n",
        "a.show()\n",
        "\n",
        "b = plt.figure(2)\n",
        "plt.hist((month_post_primary['pred_Black'] / month_post_primary['num_imgs']))\n",
        "plt.title('Dist of avg Black appeal scores by politician one month following primary')\n",
        "b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E1eTAdr_qjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How about before/after the general election?\n",
        "\n",
        "month_prior_general = data.loc[(-30 <= data.days_until_general) & (data.days_until_general < 0)]\n",
        "month_post_general = data.loc[(0 < data.days_until_general) & (data.days_until_general <= 30)]\n",
        "\n",
        "month_prior_general = month_prior_general.groupby('Name').sum().reset_index()\n",
        "month_post_general = month_post_general.groupby('Name').sum().reset_index()\n",
        "\n",
        "names3 = month_prior_general['Name'].tolist()\n",
        "names4 = month_post_general['Name'].tolist()\n",
        "\n",
        "include = [name for name in names3 if name in names4] \n",
        "\n",
        "month_prior_general = month_prior_general[month_prior_general.Name.isin(include)].reset_index().drop(columns=['index'])\n",
        "month_post_general = month_post_general[month_post_general.Name.isin(include)].reset_index().drop(columns=['index'])\n",
        "\n",
        "month_prior_general = month_prior_general.sort_values('Name')\n",
        "month_post_general = month_post_general.sort_values('Name')\n",
        "\n",
        "# Again:, use the paired t-statistic:\n",
        "ttest_rel((month_prior_general['pred_Black'] / month_prior_general['num_imgs']), (month_post_general['pred_Black'] / month_post_general['num_imgs']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GEkkHJvAkNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can we assume normality of the underlying distribution of average Black appl scores one month pre- and post-general election? \n",
        "a = plt.figure(1)\n",
        "plt.hist((month_prior_general['pred_Black'] / month_prior_general['num_imgs']))\n",
        "plt.title('Dist of avg Black appeal scores by politician one month prior to general')\n",
        "a.show()\n",
        "\n",
        "b = plt.figure(2)\n",
        "plt.hist((month_post_general['pred_Black'] / month_post_general['num_imgs']))\n",
        "plt.title('Dist of avg Black appeal scores by politician one month following general')\n",
        "b.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}